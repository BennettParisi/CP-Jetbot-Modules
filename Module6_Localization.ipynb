{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Module 4: Visual Lane Servoing and Lane Localization\n",
    "\n",
    "Now that we have our basic motion and camera imaging that we can get from our robot, we want to combine the two where it can travel down a road while staying within the lanes.\n",
    "\n",
    "This Module should follow Module 5: Road Sign Detection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from jetbot import Robot, Camera, bgr8_to_jpeg\n",
    "import cv2\n",
    "import numpy as np\n",
    "from IPython.display import display, Image, clear_output\n",
    "import time\n",
    "\n",
    "robot = Robot()\n",
    "camera = Camera.instance()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def detect_lane_markings(image: np.ndarray):\n",
    "    \"\"\"\n",
    "    Args:\n",
    "        image: An image from the robot's camera in the BGR color space (numpy.ndarray)\n",
    "    Return:\n",
    "        left_masked_img:   Masked image for the dashed-yellow line (numpy.ndarray)\n",
    "        right_masked_img:  Masked image for the solid-white line (numpy.ndarray)\n",
    "    \"\"\"\n",
    "    h, w, _ = image.shape\n",
    "    # print(image.shape)\n",
    "\n",
    "    imgbgr = image\n",
    "\n",
    "    # Convert the image to HSV for any color-based filtering\n",
    "    imghsv = cv2.cvtColor(imgbgr, cv2.COLOR_BGR2HSV)\n",
    "\n",
    "    # Most of our operations will be performed on the grayscale version\n",
    "    imggray = cv2.cvtColor(imgbgr, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "    horizon_X = 130\n",
    "    mask_ground = np.zeros((h, w), dtype=np.uint8)\n",
    "    mask_ground[int(h - horizon_X) :, :] = 1\n",
    "    # print(h,\" \" ,w,\" \" ,int(h - horizon_X[0]))\n",
    "\n",
    "    sigma = 8  # CHANGE ME\n",
    "\n",
    "    # Smooth the image using a Gaussian kernel\n",
    "    img_gaussian_filter = cv2.GaussianBlur(imggray, (0, 0), sigma)\n",
    "\n",
    "    # Convolve the image with the Sobel operator (filter) to compute the numerical derivatives in the x and y directions\n",
    "    sobelx = cv2.Sobel(img_gaussian_filter, cv2.CV_64F, 1, 0)\n",
    "    sobely = cv2.Sobel(img_gaussian_filter, cv2.CV_64F, 0, 1)\n",
    "\n",
    "    # Compute the magnitude of the gradients\n",
    "    Gmag = np.sqrt(sobelx * sobelx + sobely * sobely)\n",
    "\n",
    "    threshold_left = 5  # CHANGE ME\n",
    "    mask_mag_left = Gmag > threshold_left\n",
    "    threshold_right = 25\n",
    "    mask_mag_right = Gmag > threshold_right\n",
    "\n",
    "    white_lower_hsv = np.array([15, 3, 166])  # CHANGE ME\n",
    "    white_upper_hsv = np.array([179, 116, 255])  # CHANGE ME\n",
    "    yellow_lower_hsv = np.array([10, 75, 50])        # CHANGE ME\n",
    "    yellow_upper_hsv = np.array([35, 255, 255])  # CHANGE ME\n",
    "\n",
    "    mask_white = cv2.inRange(imghsv, white_lower_hsv, white_upper_hsv)\n",
    "    mask_yellow = cv2.inRange(imghsv, yellow_lower_hsv, yellow_upper_hsv)\n",
    "\n",
    "    mask_left = np.ones(sobelx.shape)\n",
    "    mask_left[:, int(np.floor(w / 2)) : w + 1] = 0\n",
    "    mask_right = np.ones(sobelx.shape)\n",
    "    mask_right[:, 0 : int(np.floor(w / 2))] = 0\n",
    "\n",
    "    mask_sobelx_pos = sobelx > 0\n",
    "    mask_sobelx_neg = sobelx < 0\n",
    "    mask_sobely_neg = sobely < 0\n",
    "\n",
    "    mask_left_edge = mask_ground * mask_left * mask_mag_left * mask_sobelx_neg * mask_sobely_neg * mask_yellow\n",
    "    mask_right_edge = mask_ground * mask_right * mask_mag_right * mask_sobelx_pos * mask_sobely_neg * mask_white\n",
    "    mask_lanes = cv2.bitwise_or(mask_left_edge, mask_right_edge)\n",
    "    masked_image = cv2.bitwise_and(image, image, mask=mask_ground)\n",
    "    display(Image(data=bgr8_to_jpeg(mask_lanes)))\n",
    "    display(Image(data=bgr8_to_jpeg(image)))\n",
    "\n",
    "    return mask_left_edge, mask_right_edge"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_steer_matrix_left_lane_markings(shape: Tuple[int, int]) -> np.ndarray:\n",
    "    \"\"\"\n",
    "    Args:\n",
    "        shape:              The shape of the steer matrix.\n",
    "\n",
    "    Return:\n",
    "        steer_matrix_left:  The steering (angular rate) matrix for Braitenberg-like control\n",
    "                            using the masked left lane markings (numpy.ndarray)\n",
    "    \"\"\"\n",
    "\n",
    "    width = int(shape[1] / 2)\n",
    "    height = int(shape[0])\n",
    "\n",
    "    steer_matrix_left_lane = np.zeros((height, shape[1]))\n",
    "\n",
    "    iterable = (x for x in range(width))\n",
    "    steer_matrix_left_lane_unit = np.fromiter(iterable, float)\n",
    "\n",
    "    if steer_matrix_left_lane_unit.max() != 0:\n",
    "        steer_matrix_left_lane_unit /= steer_matrix_left_lane_unit.max()\n",
    "\n",
    "    steer_matrix_left_lane[:, :width] = np.tile(steer_matrix_left_lane_unit, (height, 1)) * -0.3\n",
    "    steer_matrix_left_lane[int(height * 0.5) : -int(height * 0.2), int(width / 2) : width] = (\n",
    "        steer_matrix_left_lane[int(height * 0.5) : -int(height * 0.2), int(width / 2) : width] * 2.0\n",
    "    )\n",
    "\n",
    "    return steer_matrix_left_lane"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "while True:\n",
    "    clear_output(wait=True)\n",
    "    left, right = detect_lane_markings(camera.value)\n",
    "    time.sleep(0.01)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# AELMIGER"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from jetbot import Robot, Camera, bgr8_to_jpeg\n",
    "import cv2\n",
    "import numpy as np\n",
    "from IPython.display import display, Image, clear_output\n",
    "import time\n",
    "\n",
    "robot = Robot()\n",
    "camera = Camera.instance()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import cv2\n",
    "from scipy.optimize import lsq_linear\n",
    "import CP_constants as const\n",
    "from collections import deque"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "\n",
    " Title: Lane Detection Algorithm\n",
    " Author: Anton Elmiger\n",
    " Created: 2020-05-26\n",
    "\n",
    " Information: Class that extracts a lane from an edge image\n",
    "              and calculates the corresponding hyperbola-pair parameters\n",
    "\n",
    "              Lane Model is described in this paper https://ieeexplore.ieee.org/abstract/document/1689679\n",
    "              and in the wiki of github\n",
    "\n",
    "\"\"\"\n",
    "\n",
    "\n",
    "\n",
    "      \n",
    "class Lane_Detection:\n",
    "    def __init__(self):\n",
    "        self.v = np.arange(0, const.IMAGE_HEIGHT, 1)  # vertical points\n",
    "        self.u = np.arange(0, const.IMAGE_WIDTH, 1)  # horizontal points\n",
    "\n",
    "        self.threshold = const.BOUNDARY_THRESH\n",
    "        self.lane_width = const.LANE_WIDTH\n",
    "\n",
    "        self.h = const.HORIZON # h-horizon height\n",
    "        self.k = 0  # k-curvature of lane\n",
    "        self.bl = 0 # b-skew of left lane\n",
    "        self.br = 0 # b-skew of right lane\n",
    "        self.bc = 0 # b-skew of lane center\n",
    "        self.c = 0 # c-horizontal offset of lane\n",
    "\n",
    "        self.bcdq = deque(maxlen=const.FILTER_STRENGTH)   \n",
    "        self.bldq = deque(maxlen=const.FILTER_STRENGTH)   \n",
    "        self.brdq = deque(maxlen=const.FILTER_STRENGTH)   \n",
    "\n",
    "        self.left_lane_points = np.array([])\n",
    "        self.right_lane_points = np.array([])\n",
    "        \n",
    "        self.lane = np.array([])\n",
    "\n",
    "        # Bounds for the solving of hyperbola-pair parameters\n",
    "        # [k,bl,br,c]\n",
    "        # The constraint on c dramatically increases robustness\n",
    "        self.low_b = np.array([-500000, -8, -8, const.IMAGE_WIDTH/2 -20])\n",
    "        self.up_b = np.array([500000, 8, 8, const.IMAGE_WIDTH/2 +20])\n",
    "\n",
    "    # Calculate lane hyperbola for given parameters\n",
    "    def hyperbola_pair(self, b):\n",
    "        return self.k/(self.v-self.h)+b*(self.v-self.h)+self.c\n",
    "\n",
    "    # Function finds lane points in an edge image and classifies them to left and right lane\n",
    "    # This function is used if no lane estimate exists, or the estimation is odd\n",
    "    def get_initial_lane_points(self, edge_image):\n",
    "        image_height = edge_image.shape[0]\n",
    "        image_width = edge_image.shape[1]\n",
    "\n",
    "        # initialize lane arrays\n",
    "        left_lane_points = np.empty((image_height, 1))\n",
    "        left_lane_points[:] = np.NAN\n",
    "        right_lane_points = np.empty((image_height, 1))\n",
    "        right_lane_points[:] = np.NAN\n",
    "\n",
    "        lane_numbers = np.arange(image_width)\n",
    "        edge_image = edge_image / 255\n",
    "\n",
    "        for row in range(image_height-1, -1, -1):\n",
    "            curr_row = np.multiply(\n",
    "                (lane_numbers - image_height), edge_image[row, :])\n",
    "            points_to_the_right = np.where(curr_row > 0)[0]\n",
    "            points_to_the_left = np.where(curr_row < 0)[0]\n",
    "            if points_to_the_right.size > 0:\n",
    "                right_lane_points[row] = np.amin(points_to_the_right)\n",
    "            if points_to_the_left.size > 0:\n",
    "                left_lane_points[row] = np.amax(points_to_the_left)\n",
    "            if row == 300:\n",
    "                break\n",
    "        self.left_lane_points = left_lane_points\n",
    "        self.right_lane_points = right_lane_points\n",
    "\n",
    "    # Function finds lane points in an edge image and classifies them to left and right lane\n",
    "    def lane_points(self, edge_image):\n",
    "        image_height = edge_image.shape[0]\n",
    "\n",
    "        # initialize lane arrays\n",
    "        left_lane_points = np.empty((image_height, 1))\n",
    "        left_lane_points[:] = np.NAN\n",
    "        right_lane_points = np.empty((image_height, 1))\n",
    "        right_lane_points[:] = np.NAN\n",
    "\n",
    "        # get the \"bounding\" lanes to filter outliers\n",
    "        # only points between the bounds are considered inliers\n",
    "        left_max_bound, left_min_bound, right_max_bound, right_min_bound = self.generate_bounding_lanes()\n",
    "\n",
    "        # only considere points that are below the horizon (plus some extra space for robustness) if the horizon is in the image\n",
    "        horizon_index = int(max(self.h+20,0))\n",
    "\n",
    "        # get the 2D image position of edge pixels that are below the horizon index\n",
    "        nonzero = cv2.findNonZero(edge_image[horizon_index:]).reshape((-1,2)).T\n",
    "        # offset the Y-Coordinate by the horizon index\n",
    "        nonzero[1] += horizon_index\n",
    "\n",
    "        # classify all points in left bounding area as left lane points\n",
    "        left_p = nonzero.T[(nonzero[0] < left_max_bound[nonzero[1]]) & (nonzero[0] > left_min_bound[nonzero[1]])]\n",
    "\n",
    "        # classify all points in right bounding area as left right points\n",
    "        # the flipping of the array is imortant for the next step\n",
    "        right_p = np.flipud(nonzero.T[(nonzero[0] < right_max_bound[nonzero[1]]) & (nonzero[0] > right_min_bound[nonzero[1]])])\n",
    "\n",
    "        # for each vertical row in the image that contains a left lane point ->\n",
    "        # place the point that is closest the the centerline into the left lane points array\n",
    "        np.put(left_lane_points,left_p[:,1],left_p[:,0])\n",
    "        \n",
    "        # for each vertical row in the image that contains a right lane point ->\n",
    "        # place the point that is closest the the centerline into the right lane points array\n",
    "        np.put(right_lane_points,right_p[:,1],right_p[:,0])\n",
    "\n",
    "        self.left_lane_points = left_lane_points\n",
    "        self.right_lane_points = right_lane_points\n",
    "\n",
    "\n",
    "    # Function returns lane lines, that are left and right of the estimated lane lines\n",
    "    # These bounding lines are then used to define an inlier area\n",
    "    def generate_bounding_lanes(self):\n",
    "        # horizontal points left lane\n",
    "        left_max = self.hyperbola_pair(self.bl+(self.bc-self.bl)/self.threshold)\n",
    "        # horizontal points left lane\n",
    "        left_min = self.hyperbola_pair(self.bl-(self.bc-self.bl)/self.threshold)\n",
    "        # horizontal points left lane\n",
    "        right_max = self.hyperbola_pair(self.br+(self.bc-self.bl)/self.threshold)\n",
    "        # horizontal points left lane\n",
    "        right_min = self.hyperbola_pair(self.br-(self.bc-self.bl)/self.threshold)\n",
    "        return left_max, left_min, right_max, right_min\n",
    "\n",
    "\n",
    "    # Function solves for hyperbola-pair lane parameters\n",
    "    # More info is in the paper listed at the top of this file\n",
    "    def solve_lane(self):\n",
    "        # generate matrices for lsq solver\n",
    "        A, b = self.preprocess_for_solving()\n",
    "        # returning the solved parameters (k,bl,br,c)\n",
    "        self.solving_lane_params(A, b)\n",
    "\n",
    "    def preprocess_for_solving(self):\n",
    "        l = self.left_lane_points\n",
    "        r = self.right_lane_points\n",
    "        # following lines create A matrix  and b vector for least square porblem\n",
    "        l_ind = ~np.isnan(l)\n",
    "        r_ind = ~np.isnan(r)\n",
    "        l_num = l[l_ind]\n",
    "        r_num = r[r_ind]\n",
    "        vl = self.v[l_ind.flatten()]\n",
    "        vr = self.v[r_ind.flatten()]\n",
    "        l_num = l_num.reshape((len(l_num), 1))\n",
    "        r_num = r_num.reshape((len(r_num), 1))\n",
    "        vl = vl.reshape(l_num.shape)\n",
    "        vr = vr.reshape(r_num.shape)\n",
    "\n",
    "        lh = (vl-self.h)\n",
    "        lA = 1/lh\n",
    "        rh = (vr-self.h)\n",
    "        rA = 1/rh\n",
    "        ones = np.ones(l_num.shape)\n",
    "        zeros = np.zeros(l_num.shape)\n",
    "        LA = np.hstack((np.hstack((lA, lh)), np.hstack((zeros, ones))))\n",
    "        ones = np.ones(r_num.shape)\n",
    "        zeros = np.zeros(r_num.shape)\n",
    "        RA = np.hstack((np.hstack((rA, zeros)), np.hstack((rh, ones))))\n",
    "        A = np.vstack((LA, RA))\n",
    "        b = (np.concatenate((l_num, r_num))).flatten()\n",
    "        return A, b\n",
    "\n",
    "    def solving_lane_params(self, A, b):\n",
    "        x = lsq_linear(A, b, bounds=(self.low_b, self.up_b), method='bvls', max_iter = 3).x\n",
    "        # set new lane model param from least square solution\n",
    "        self.k = x[0]\n",
    "        self.bl=x[1]\n",
    "        self.br=x[2]\n",
    "        self.c = x[3]\n",
    "        self.bc = (x[1]+x[2])/2\n",
    "        # calc lane points\n",
    "        self.lane = self.hyperbola_pair(self.bc)\n",
    "\n",
    "    # function corrects false lane lines or missing lane lines\n",
    "    def lane_sanity_checks(self,edge_image):\n",
    "        #lane not found\n",
    "        if self.k == 0:\n",
    "            self.get_initial_lane_points(edge_image)\n",
    "            self.solve_lane()\n",
    "\n",
    "        #Only one lane found\n",
    "        self.interpolate_missing_lane()            \n",
    "\n",
    "        #Lane width not correct size\n",
    "        self.adjust_lane_width()            \n",
    "\n",
    "        #Vehicle not on lane -> recenter lane line\n",
    "        self.recenter_lane()\n",
    "    \n",
    "        #smooth lane\n",
    "        self.filter_lane()\n",
    "         \n",
    "        self.lane = self.hyperbola_pair(self.bc)\n",
    "\n",
    "    def interpolate_missing_lane(self):\n",
    "        #Only one lane found\n",
    "        if ~np.isfinite(self.left_lane_points).any():\n",
    "            self.bl = self.br-self.lane_width-0.3\n",
    "            self.bc = (self.bl+self.br)/2            \n",
    "        if ~np.isfinite(self.right_lane_points).any():\n",
    "            self.br = self.bl+self.lane_width+0.3\n",
    "            self.bc = (self.bl+self.br)/2            \n",
    "\n",
    "    def adjust_lane_width(self):\n",
    "        #Lane width not correct size\n",
    "        if abs(self.bl-self.br)<(self.lane_width*0.8) or abs(self.bl-self.br)>(self.lane_width)*1.2:\n",
    "            length_l = np.count_nonzero(~np.isnan(self.left_lane_points))\n",
    "            length_r = np.count_nonzero(~np.isnan(self.right_lane_points))\n",
    "            if length_l > length_r:\n",
    "                self.br = self.bl+self.lane_width\n",
    "            else:\n",
    "                self.bl = self.br-self.lane_width\n",
    "            self.bc = (self.bl+self.br)/2            \n",
    "\n",
    "    def recenter_lane(self):\n",
    "        #Vehicle not on lane -> recenter lane line\n",
    "        if self.bc > (self.lane_width/1.1):\n",
    "            self.bl=self.bl-self.lane_width\n",
    "            self.br=self.br-self.lane_width\n",
    "\n",
    "        if self.bc < (-self.lane_width/1.1):\n",
    "            self.bl=self.bl+self.lane_width\n",
    "            self.br=self.br+self.lane_width\n",
    "\n",
    "    def filter_lane(self):\n",
    "        self.bc = (self.bl+self.br)/2 \n",
    "        self.bcdq.append(self.bc)\n",
    "        self.bc = sum(bc for bc in self.bcdq)/len(self.bcdq)\n",
    "        self.bldq.append(self.bl)\n",
    "        self.bl = sum(bc for bc in self.bldq)/len(self.bldq)\n",
    "        self.brdq.append(self.br)\n",
    "        self.br = sum(bc for bc in self.brdq)/len(self.brdq)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "\n",
    " Title: Transform Points\n",
    " Author: Anton Elmiger\n",
    " Created: 2020-05-26\n",
    "\n",
    " Information: Class used to transform Points between camera space and world\n",
    "              space\n",
    "\"\"\"\n",
    "import numpy as np\n",
    "import CP_constants as const\n",
    "from scipy.spatial.transform import Rotation as R\n",
    "\n",
    "\n",
    "class Transform_Points:\n",
    "    def __init__(self,_cam_angle=45):\n",
    "        # cam angle from horizontal down in [degrees]]\n",
    "        cam_angle = _cam_angle\n",
    "\n",
    "        self.rot_mat_inv = R.from_euler(\n",
    "            'xyz', [-90-cam_angle, 0, -90], degrees=True).as_matrix()\n",
    "        self.rot_mat = np.linalg.inv(self.rot_mat_inv)\n",
    "\n",
    "        # fov = 160 #fov in degrees/2\n",
    "        width = const.IMAGE_WIDTH\n",
    "        height = const.IMAGE_HEIGHT\n",
    "        aspect_ratio = width / height\n",
    "        fx = 417/2  # width / (np.tan(np.radians(fov) / 2) * 2)\n",
    "        fy = fx\n",
    "        self.cameraMatrix = np.array(\n",
    "            [[fx, 0, width / 2], [0, fy, height / 2], [0, 0, 1]])\n",
    "        self.cameraMatrixInv = np.linalg.inv(self.cameraMatrix)\n",
    "        self.tt = -np.array([[0.182], [0.], [0.195]])\n",
    "        self.rotationMatrix = self.rot_mat  # np.empty([3, 3])\n",
    "        self.tvec = self.rotationMatrix @ self.tt\n",
    "        self.rotationMatrixInv = np.linalg.inv(self.rotationMatrix)\n",
    "\n",
    "        self.poly_koeff = np.array([0.0, 0.0, 0.0])\n",
    "\n",
    "    def imagePoint_to_worldPoint(self, imgPoints):\n",
    "        imgPoints = imgPoints.T\n",
    "        n, m = imgPoints.shape\n",
    "\n",
    "        imgPoints = np.vstack([imgPoints, np.ones((1, m))])\n",
    "        leftSideMat = self.rotationMatrixInv.dot(\n",
    "            self.cameraMatrixInv).dot(imgPoints)\n",
    "        rightSideMat = self.rotationMatrixInv.dot(self.tvec)\n",
    "        s = (0 + rightSideMat[2, 0])/leftSideMat[2, :]\n",
    "        return self.rotationMatrixInv.dot(s*self.cameraMatrixInv.dot(imgPoints)-self.tvec)\n",
    "\n",
    "    def worldPoint_to_imagePoint(self, worldPoint):\n",
    "        worldPoint = worldPoint.reshape(-1, 1)\n",
    "        rightSideMat = self.cameraMatrix.dot(\n",
    "            self.rotationMatrix.dot(worldPoint)+self.tvec)\n",
    "        return np.round((rightSideMat/rightSideMat[2, 0])[0:2])\n",
    "\n",
    "    def transform_lane_to_poly(self, lane_class):\n",
    "        lane_points = np.hstack((lane_class.lane.reshape(\n",
    "            (-1, 1)), lane_class.v.reshape((-1, 1))))\n",
    "        lane_points = lane_points[int(max(const.HORIZON+20, 20)):, :]\n",
    "        worldCoord = self.imagePoint_to_worldPoint(lane_points).T\n",
    "        self.poly_koeff = np.polyfit(worldCoord[:, 0], worldCoord[:, 1], 2)\n",
    "\n",
    "    def send_lane_tcp(self, conn):\n",
    "        conn.sendall(self.poly_koeff.astype(np.float64).tobytes())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\"\"\"\n",
    "\n",
    " Title: Visualization Class\n",
    " Author: Anton Elmiger\n",
    " Created: 2020-05-21\n",
    "\n",
    " Information: Class to visualize the opencv images\n",
    "\n",
    "\"\"\"\n",
    "import numpy as np\n",
    "import cv2\n",
    "import CP_constants as const\n",
    "import math\n",
    "\n",
    "\n",
    "class Visualization:\n",
    "        def __init__(self):\n",
    "            self.array_of_imgs = []\n",
    "            self.vidArray = []\n",
    "        \n",
    "        def clear_imgs(self):\n",
    "            self.array_of_imgs = []\n",
    "\n",
    "        def append_img(self,img):\n",
    "            res_img = cv2.resize(img, (640, 480))\n",
    "            if len(img.shape) == 2:\n",
    "                res_img = cv2.cvtColor(res_img, cv2.COLOR_GRAY2RGB)\n",
    "            self.array_of_imgs.append(res_img)\n",
    "\n",
    "        def draw_lane_lines(self,img,lane_class):\n",
    "            lane_c = lane_class.hyperbola_pair(lane_class.bc)\n",
    "            lane_r = lane_class.hyperbola_pair(lane_class.br)\n",
    "            lane_l = lane_class.hyperbola_pair(lane_class.bl)\n",
    "\n",
    "            draw_points_c = (np.asarray([lane_c, lane_class.v]).T).astype(np.int32)\n",
    "            draw_points_l = (np.asarray([lane_l, lane_class.v]).T).astype(np.int32)\n",
    "            draw_points_r = (np.asarray([lane_r, lane_class.v]).T).astype(np.int32)\n",
    "\n",
    "            cv2.polylines(img, [draw_points_c[int(max(const.HORIZON+20,30)):]], False, (0,255,0),10)\n",
    "            cv2.polylines(img, [draw_points_l[int(max(const.HORIZON+20,30)):]], False, (255,0,0),4)\n",
    "            cv2.polylines(img, [draw_points_r[int(max(const.HORIZON+20,30)):]], False, (0,0,255),4) \n",
    "            return img\n",
    "        \n",
    "        def draw_lane_points(self,img,lane_class):\n",
    "            draw_points_l = (np.asarray([lane_class.left_lane_points.reshape(-1,), lane_class.v]).T).astype(np.int32)\n",
    "            for point in draw_points_l:\n",
    "                img = cv2.circle(img,tuple(point),8,(255,0,0),-1)\n",
    "\n",
    "            draw_points_r = (np.asarray([lane_class.right_lane_points.reshape(-1,), lane_class.v]).T).astype(np.int32)\n",
    "            for point in draw_points_r:\n",
    "                img = cv2.circle(img,tuple(point),8,(0,0,255),-1)\n",
    "                            \n",
    "\n",
    "        def show_imgs(self):\n",
    "            n_images = len(self.array_of_imgs)\n",
    "            rows = math.floor(n_images/3)+1\n",
    "            row_imgs = self.array_of_imgs[0]\n",
    "            for i in range(n_images-1):\n",
    "                row_imgs = np.hstack((row_imgs, self.array_of_imgs[i+1]))\n",
    "            cv2.imshow(\"Imgs\", row_imgs)\n",
    "            cv2.waitKey(1)\n",
    "            if const.WRITE_VIDEO:\n",
    "                self.vidArray.append(row_imgs)\n",
    "\n",
    "        def write_video(self):\n",
    "            height, width, layers = self.vidArray[0].shape\n",
    "            size = (width,height)\n",
    "\n",
    "            out = cv2.VideoWriter('vidOut.avi',cv2.VideoWriter_fourcc(*'DIVX'), 15, size)\n",
    " \n",
    "            for i in range(len(self.vidArray)):\n",
    "                out.write(self.vidArray[i])\n",
    "            out.release()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def edge_detection(img):\n",
    "    gray = cv2.cvtColor(img, cv2.COLOR_RGB2GRAY).astype(np.float)       # convert to gray\n",
    "    mask_ground = np.ones(img.shape, dtype=np.uint8)\n",
    "    mask_ground = np.zeros(img.shape, dtype=np.uint8)\n",
    "    mask_ground[int(img.shape[0] - const.HORIZON) :, :] = 1\n",
    "    blurredGray = cv2.blur(gray*mask_ground, (3, 3))                                # blur img for robustness\n",
    "    blurredSobelImg = cv2.Sobel(blurredGray, cv2.CV_8U, 1, 0, ksize=1)  # calculate sobel gradient\n",
    "    ret, threshSobel = cv2.threshold(                                   # soebel img to binary by threshold\n",
    "        blurredSobelImg, 7, 255, cv2.THRESH_BINARY)\n",
    "    kernel = np.ones((3, 3), np.uint8)                                  # erode image to remove noise\n",
    "    erodedSobel = cv2.erode(threshSobel, kernel, iterations=1)          # erode image to remove noise\n",
    "    return erodedSobel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "visual = Visualization()\n",
    "ld = Lane_Detection()\n",
    "tp = Transform_Points()\n",
    "\n",
    "img = np.array(camera.value)\n",
    "\n",
    "edge_image = edge_detection(img)            # Detect Edges in image\n",
    "\n",
    "ld.get_initial_lane_points(edge_image)      # Apply Lane initialization on first image\n",
    "ld.solve_lane()                             # Solve lane model parameters from lane points\n",
    "ld.lane_sanity_checks(edge_image)           # Apply corrections to lane model\n",
    "tp.transform_lane_to_poly(ld)               # Calculate polynomial coeff from lane model\n",
    "\n",
    "visual.draw_lane_lines(img, ld)                             # Draw lane model lines on image\n",
    "edge_image = cv2.cvtColor(edge_image, cv2.COLOR_GRAY2RGB)   # Generate Edge Image\n",
    "visual.draw_lane_points(edge_image, ld)                     # Draw lane edge points on image\n",
    "display(Image(data=bgr8_to_jpeg(img)))                      # Display img with drawing\n",
    "display(Image(data=bgr8_to_jpeg(edge_image)))                      # Display img with drawing\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "while const.VISUALIZE:\n",
    "       clear_output(wait = True)\n",
    "       img = np.array(camera.value)\n",
    "\n",
    "       for i in range(2):                      # Solve for lane model multiple times for convergence\n",
    "              ld.lane_points(edge_image)      \n",
    "              ld.solve_lane()                     # Solve lane model parameters from lane points\n",
    "              ld.lane_sanity_checks(edge_image)   # Apply corrections to lane model\n",
    "       tp.transform_lane_to_poly(ld)           # Calculate polynomial coeff from lane model\n",
    "\n",
    "       # visual.clear_imgs()                                         # Clear Images to show every iteration\n",
    "       visual.draw_lane_lines(img, ld)                             # Draw lane model lines on image\n",
    "       edge_image = cv2.cvtColor(edge_image, cv2.COLOR_GRAY2RGB)   # Generate Edge Image\n",
    "       visual.draw_lane_points(edge_image, ld)                     # Draw lane edge points on image\n",
    "       display(Image(data=bgr8_to_jpeg(img)))                      # Append img for drawing\n",
    "       # visual.append_img(edge_image)                               # Append img for drawing\n",
    "       # img = vid.bev(img)                                          # Birds Eye View transformation\n",
    "       # visual.append_img(img)                                      # Append img for drawing\n",
    "       # visual.show_imgs()                                          # Show images that were appended for drawing"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
