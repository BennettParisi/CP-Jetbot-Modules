{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Module 3: Camera and Computer Vision Basics\n",
    "\n",
    "Now that we have basic motion and odometery implemented, we will look at the camera on the <span style=\"color:#154734\">Jetbot</span> and how images are handled within Python.\n",
    "\n",
    "This Module should follow Module 2: Path Following"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As always, we need to first initialize some of the packages and objects for our <span style=\"color:#154734\">Jetbot</span>."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# sudo pip install --upgrade pip\n",
    "# sudo pip install opencv-python"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from jetbot import Robot, Camera, bgr8_to_jpeg\n",
    "import cv2\n",
    "import numpy as np\n",
    "from IPython.display import display, Image, clear_output\n",
    "import time\n",
    "\n",
    "robot = Robot()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There are now a few new items we are importing into our code now. In no particular order, they are:\n",
    "- from Jetbot import Camera, bgr8_to_jpeg\n",
    "- import cv2\n",
    "- import numpy as np\n",
    "- from IPython.display import display, Image, clear_output\n",
    "- import time\n",
    "\n",
    "Each item is important to making our camera function and display, while also giving us the ability to modify our image to our liking. Their functions and usage will be described following each of the code blocks below."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Taking Pictures"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize our camera\n",
    "camera = Camera.instance()\n",
    "\n",
    "# Save image data (modified to be numpy array)\n",
    "image = np.array(camera.value)\n",
    "\n",
    "jpeg_image = bgr8_to_jpeg(image)\n",
    "\n",
    "# Display image within Jupyter Notebook\n",
    "display(Image(data=jpeg_image))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is our basic method of taking an image and displaying it within Jupyter Notebook.\n",
    "\n",
    "First, we need to initialize our camera, as shown in the first line. When this is done, the image that the camera takes is stored in *camera.value*.\n",
    "\n",
    "Knowing where the image is stored, we can assign that to a variable as shown in the second line. Additionally, this value is stored as a bgr8 file (standing for blue, green, red, 8 bit), and the np.array function basically simplifies the way it is stored (in an easier to understand format).\n",
    "\n",
    "However, to display the image, we need to store it as a jpeg image. Luckily, jetbot has a function for this labeled as bgr8_to_jpeg. By calling this function with the image as an argument, we now have an image stored as a JPEG.\n",
    "\n",
    "Lastly, we need to display the image in Jupyter Notebook. One of the ways we display any outputs is using the display() command. But simply passing jpeg_image to display will print the data as it is stored (with numbers and characters), and not as a picture. Therefore, we need the Image() command, and pass the jpeg_image to the argument data within.\n",
    "\n",
    "This will only output one picture, since the block is only being run once. If we want to continuously output a live feed from the camera, we can implement these features in a loop as shown below."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-info\">\n",
    "Opportunity for Activity\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "while True:\n",
    "    clear_output(wait = True)\n",
    "    image = np.array(camera.value)\n",
    "    jpeg_image = bgr8_to_jpeg(image)\n",
    "    display(Image(data = jpeg_image))\n",
    "    time.sleep(0.5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> Note that the time.sleep(0.5) is used to set the frame rate, where a new image is displayed every 0.5 seconds. To make it faster, we can decrease the time within, effectively increasing the frequency at which the image updates.\n",
    "\n",
    "In addition, we now need to include clear_output(wait = True). This command will replace the image below the block, so that it won't constantly display new pictures (You can see the effects of what happens if you remove that command).\n",
    "\n",
    "### Editing/Modifying Images\n",
    "\n",
    "Now for one of the most important part of the lessons for this module, is how to operate computer vision techniques on the images. This will be primarily using opencv, otherwise known as cv2. The code below shows some options for what can be accomplished"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-danger\">\n",
    "You will likely need to interrupt your kernel before you can continue with the square block above (otherwise it will be stuck in the loop).\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_and_display_image():\n",
    "    image = np.array(camera.value)\n",
    "    gray_image = cv2.cvtColor(image, cv2.COLOR_RGB2GRAY)\n",
    "    display(Image(data=bgr8_to_jpeg(gray_image)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Similar to before, we must save our image from the camera as a numpy array. But now, we will perform operations on the image before we display them.\n",
    "\n",
    "One such operation is changing the image to grayscale. As seen above, the code takes the image, and modifies it from RGB to Gray. Afterwards, we can display the image (after transforming it to a jpeg) and you will see the image from your camera in gray.\n",
    "\n",
    "Similar to before, we can create a live feed using a loop again."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-info\">\n",
    "Opportunity for Activity\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "while True:\n",
    "    clear_output(wait=True)\n",
    "    process_and_display_image()\n",
    "    time.sleep(0.01)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-info\">\n",
    "Will probably need to go more in depth on computer vision and other functions that are possible, but don't really want to do it right now. But likely could look at masking/color detection and edge detection in preparation for next module.\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Camera Calibration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# termination criteria\n",
    "criteria = (cv2.TERM_CRITERIA_EPS + cv2.TERM_CRITERIA_MAX_ITER, 30, 0.001)\n",
    "\n",
    "# prepare object points, like (0,0,0), (1,0,0), (2,0,0) ....,(6,5,0)\n",
    "objp = np.zeros((6*7,3), np.float32)\n",
    "objp[:,:2] = np.mgrid[0:7,0:6].T.reshape(-1,2)\n",
    "\n",
    "# Arrays to store object points and image points from all the images.\n",
    "objpoints = [] # 3d point in real world space\n",
    "imgpoints = [] # 2d points in image plane.\n",
    "\n",
    "count = 0\n",
    "\n",
    "while count < 10:\n",
    "    clear_output(wait=True)\n",
    "\n",
    "    img = camera.value\n",
    "    gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "    # Find the chess board corners\n",
    "    ret, corners = cv2.findChessboardCorners(gray, (7,6), None)\n",
    "\n",
    "    # If found, add object points, image points (after refining them)\n",
    "    if ret == True:\n",
    "        objpoints.append(objp)\n",
    "\n",
    "        corners2 = cv2.cornerSubPix(gray,corners, (11,11), (-1,-1), criteria)\n",
    "        imgpoints.append(corners2)\n",
    "\n",
    "        # Draw and display the corners\n",
    "        cv2.drawChessboardCorners(img, (7,6), corners2, ret)\n",
    "    display(Image(data=bgr8_to_jpeg(img)))\n",
    "    time.sleep(0.01)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
