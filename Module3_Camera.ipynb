{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Module 3: Camera and Computer Vision Basics\n",
    "\n",
    "Now that we have basic motion and odometery implemented, we will look at the camera on the <span style=\"color:#154734\">Jetbot</span> and how images are handled within Python.\n",
    "\n",
    "This Module should follow Module 2: Path Following"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As always, we need to first initialize some of the packages and objects for our <span style=\"color:#154734\">Jetbot</span>."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# sudo pip install --upgrade pip\n",
    "# sudo pip install opencv-python"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from jetbot import Robot, Camera, bgr8_to_jpeg\n",
    "import cv2\n",
    "import numpy as np\n",
    "import ipywidgets as widgets\n",
    "from IPython.display import display, Image, clear_output\n",
    "import time\n",
    "\n",
    "robot = Robot()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There are now a few new items we are importing into our code now. In no particular order, they are:\n",
    "- from Jetbot import Camera, bgr8_to_jpeg\n",
    "- import cv2\n",
    "- import numpy as np\n",
    "- from IPython.display import display, Image, clear_output\n",
    "- import time\n",
    "\n",
    "Each item is important to making our camera function and display, while also giving us the ability to modify our image to our liking. Their functions and usage will be described following each of the code blocks below."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Taking Pictures"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize our camera\n",
    "camera = Camera.instance()\n",
    "\n",
    "# Save image data (modified to be numpy array)\n",
    "image = np.array(camera.value)\n",
    "\n",
    "jpeg_image = bgr8_to_jpeg(image)\n",
    "\n",
    "# Display image within Jupyter Notebook\n",
    "display(Image(data=jpeg_image))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is our basic method of taking an image and displaying it within Jupyter Notebook.\n",
    "\n",
    "First, we need to initialize our camera, as shown in the first line. When this is done, the image that the camera takes is stored in *camera.value*.\n",
    "\n",
    "Knowing where the image is stored, we can assign that to a variable as shown in the second line. Additionally, this value is stored as a bgr8 file (standing for blue, green, red, 8 bit), and the np.array function basically simplifies the way it is stored (in an easier to understand format).\n",
    "\n",
    "However, to display the image, we need to store it as a jpeg image. Luckily, jetbot has a function for this labeled as bgr8_to_jpeg. By calling this function with the image as an argument, we now have an image stored as a JPEG.\n",
    "\n",
    "Lastly, we need to display the image in Jupyter Notebook. One of the ways we display any outputs is using the display() command. But simply passing jpeg_image to display will print the data as it is stored (with numbers and characters), and not as a picture. Therefore, we need the Image() command, and pass the jpeg_image to the argument data within.\n",
    "\n",
    "This will only output one picture, since the block is only being run once. If we want to continuously output a live feed from the camera, we can implement these features in a loop as shown below."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-info\">\n",
    "Opportunity for Activity\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "while True:\n",
    "    clear_output(wait = True)\n",
    "    image = np.array(camera.value)\n",
    "    jpeg_image = bgr8_to_jpeg(image)\n",
    "    display(Image(data = jpeg_image))\n",
    "    time.sleep(0.5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> Note that the time.sleep(0.5) is used to set the frame rate, where a new image is displayed every 0.5 seconds. To make it faster, we can decrease the time within, effectively increasing the frequency at which the image updates.\n",
    "\n",
    "In addition, we now need to include clear_output(wait = True). This command will replace the image below the block, so that it won't constantly display new pictures (You can see the effects of what happens if you remove that command).\n",
    "\n",
    "### Editing/Modifying Images\n",
    "\n",
    "Now for one of the most important part of the lessons for this module, is how to operate computer vision techniques on the images. This will be primarily using opencv, otherwise known as cv2. The code below shows some options for what can be accomplished"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-danger\">\n",
    "You will likely need to interrupt your kernel before you can continue with the square block above (otherwise it will be stuck in the loop).\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_and_display_image():\n",
    "    image = np.array(camera.value)\n",
    "    gray_image = cv2.cvtColor(image, cv2.COLOR_RGB2GRAY)\n",
    "    display(Image(data=bgr8_to_jpeg(gray_image)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Similar to before, we must save our image from the camera as a numpy array. But now, we will perform operations on the image before we display them.\n",
    "\n",
    "One such operation is changing the image to grayscale. As seen above, the code takes the image, and modifies it from RGB to Gray. Afterwards, we can display the image (after transforming it to a jpeg) and you will see the image from your camera in gray.\n",
    "\n",
    "Similar to before, we can create a live feed using a loop again."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-info\">\n",
    "Opportunity for Activity\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "while True:\n",
    "    clear_output(wait=True)\n",
    "    process_and_display_image()\n",
    "    time.sleep(0.01)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Lastly, this can also be accomplished via threading, which allows it to run simultaneousy with other code. But to do it this way, it needs to be in a jupyter notebook widget."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import threading\n",
    "image = widgets.Image(format='jpeg', width=300, height=300)\n",
    "display(image)\n",
    "\n",
    "def update_image():\n",
    "    while True:\n",
    "        image.value = bgr8_to_jpeg(camera.value)\n",
    "        time.sleep(0.01)\n",
    "\n",
    "threading.Thread(target=update_image, daemon=True).start()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-info\">\n",
    "Will probably need to go more in depth on computer vision and other functions that are possible, but don't really want to do it right now. But likely could look at masking/color detection and edge detection in preparation for next module.\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Camera Calibration"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If you'll notice on the images being displayed, there is quite a bit of distortion in the image. It becomes especially clear if you hold something with a straight edge in front of it, like a piece of paper, the camera completely bends and curves the edge.\n",
    "\n",
    "To fix this, we need to calibrate our camera, and get a specific matrix that can be used to clarify and undistort our image. This will be done using a checkerboard pattern and many images to calculate.\n",
    "\n",
    "The process is simple, take the checkerboard pattern, move it around, and click \"Save Image\" when you see the array of dots highlighting each of the checkerboard's internal corners. You should collect around 5-10 images, all at different locations, and the more pictures, the better the calibration will be."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import ipywidgets as widgets\n",
    "from IPython.display import display\n",
    "import threading\n",
    "import time\n",
    "import os\n",
    "\n",
    "# 1. Checkerboard Parameters (inner corners, square size in meters)\n",
    "CHECKERBOARD = (7, 5)  # 7 columns, 5 rows of inner corners\n",
    "SQUARE_SIZE = 0.024  # in meters (e.g., 24mm squares)\n",
    "\n",
    "# termination criteria\n",
    "criteria = (cv2.TERM_CRITERIA_EPS + cv2.TERM_CRITERIA_MAX_ITER, 30, 0.001)\n",
    "\n",
    "# prepare object points, like (0,0,0), (1,0,0), (2,0,0) ....,(6,5,0)\n",
    "objp = np.zeros((CHECKERBOARD[0]*CHECKERBOARD[1],3), np.float32)\n",
    "objp[:,:2] = np.mgrid[0:CHECKERBOARD[0],0:CHECKERBOARD[1]].T.reshape(-1,2)\n",
    "objp *= SQUARE_SIZE\n",
    "\n",
    "# Arrays to store object points and image points from all the images.\n",
    "objpoints = [] # 3d point in real world space\n",
    "imgpoints = [] # 2d points in image plane.\n",
    "\n",
    "# 1. Setup Widgets\n",
    "image = widgets.Image(format='jpeg', width=300, height=300)\n",
    "save_button = widgets.Button(description='Save Image')\n",
    "saved_count = 0\n",
    "status_label = widgets.Label(value='Ready')\n",
    "display(widgets.VBox([image, save_button, status_label]))\n",
    "ret = False\n",
    "\n",
    "\n",
    "\n",
    "# 3. Image Update Function (Threaded)\n",
    "def update_image_loop():\n",
    "    global ret\n",
    "    while True:\n",
    "        frame = camera.value\n",
    "        gray = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)\n",
    "        ret, corners = cv2.findChessboardCorners(gray, CHECKERBOARD, None)\n",
    "        # If found, add object points, image points (after refining them)\n",
    "        if ret == True:\n",
    "            corners2 = cv2.cornerSubPix(gray,corners, (11,11), (-1,-1), criteria)\n",
    "\n",
    "            # Draw and display the corners\n",
    "            cv2.drawChessboardCorners(frame, CHECKERBOARD, corners2, ret)\n",
    "        image.value = bgr8_to_jpeg(frame)\n",
    "        time.sleep(0.01)  # control the update rate\n",
    "\n",
    "# 3. Button Callback to Save Image\n",
    "SAVE_DIR = \"calibration_images\"\n",
    "os.makedirs(SAVE_DIR, exist_ok=True)\n",
    "\n",
    "def save_image_callback(b):\n",
    "    global saved_count\n",
    "    global objpoints\n",
    "    global imgpoints\n",
    "    frame = camera.value\n",
    "    gray = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)\n",
    "    ret, corners = cv2.findChessboardCorners(gray, CHECKERBOARD, None)\n",
    "    # If found, add object points, image points (after refining them)\n",
    "    if ret == True:\n",
    "        objpoints.append(objp)\n",
    "\n",
    "        corners2 = cv2.cornerSubPix(gray,corners, (11,11), (-1,-1), criteria)\n",
    "        imgpoints.append(corners2)\n",
    "    if frame:\n",
    "        filename = f\"image_{saved_count}.jpg\"\n",
    "        filepath = os.path.join(SAVE_DIR, filename)\n",
    "        with open(filepath, 'wb') as f:\n",
    "            f.write(frame)\n",
    "        status_label.value = f\"✅ Saved {filename}\"\n",
    "        saved_count += 1\n",
    "    else:\n",
    "        status_label.value = \"⚠️ No image available.\"\n",
    "\n",
    "# 4. Connect Callback\n",
    "save_button.on_click(save_image_callback)\n",
    "\n",
    "# 5. Start Image Update Thread (non-blocking)\n",
    "threading.Thread(target=update_image_loop, daemon=True).start()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "With our images now saved and the points stored, we need to run the following code to calculate our camera's parameters. Move one of the images in the \"calibration_images\" folder outside to the same place where the notebook is stored (pick the one with the most visible distortion), and change in the code below so the imread is reading the correct filename. Afterwards, an image will be saved called \"calib_result\" with a less distorted image."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ret, mtx, dist, rvecs, tvecs = cv2.calibrateCamera(objpoints, imgpoints, image.value.shape[::-1], None, None)\n",
    "\n",
    "# Change name of image file here!!!\n",
    "img = cv2.imread('image_?.jpg')\n",
    "h,  w = img.shape[:2]\n",
    "newcameramtx, roi = cv2.getOptimalNewCameraMatrix(mtx, dist, (w,h), 1, (w,h))\n",
    "\n",
    "# undistort\n",
    "dst = cv2.undistort(img, mtx, dist, None, newcameramtx)\n",
    "\n",
    "# crop the image\n",
    "x, y, w, h = roi\n",
    "dst = dst[y:y+h, x:x+w]\n",
    "display(Image(data=bgr8_to_jpeg(dst)))\n",
    "cv2.imwrite('calib_result.png', dst)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Hopefully, you now see an image that has less distortion where the edges are much straighter, like they're supposed to be. Knowing that this works, we need to save our camera parameters (known as the intrinsic parameters) that we used to undistort our image, which will be used later on.\n",
    "\n",
    "The camera's intrinsic parameters matrix will be stored in the following form:\n",
    "\n",
    " \\begin{bmatrix}\n",
    "f_x & 0 & c_x \\\\\n",
    "0 & f_y & c_y \\\\\n",
    "0 & 0 & 1 \\\\\n",
    "\\end{bmatrix}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(mtx)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "But we want it in the form:\n",
    "\\begin{bmatrix}\n",
    "f_x, & f_y, & c_x, & c_y, \\\\\n",
    "\\end{bmatrix}\n",
    "\n",
    "So taking the values from the printed matrix above, write a variable that stores the intrinsic parameters in that format."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cam_mtx = ?\n",
    "print(cam_mtx)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Keep track of that variable, we will be using it in the next module."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
