{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "661cd3b0",
   "metadata": {},
   "source": [
    "# Module 6: Line/Lane Tracking\n",
    "\n",
    "This is where we start to get to the main application for our Jetbot. We want to be able to detect the lane and find the trajectory for which our robot should follow. This will involve some of the lessons we have previously learned, and applying them in a separate context.\n",
    "\n",
    "Below is our normal starter code for initializing all variables and packages. An image should appear to ensure it is working properly."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2088876e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from jetbot import Robot, Camera, bgr8_to_jpeg\n",
    "import cv2\n",
    "import numpy as np\n",
    "import ipywidgets as widgets\n",
    "from scipy.signal import medfilt\n",
    "from IPython.display import display, Image, clear_output\n",
    "import time\n",
    "\n",
    "robot = Robot()\n",
    "# Initialize our camera\n",
    "camera = Camera.instance()\n",
    "\n",
    "# Save image data (modified to be numpy array)\n",
    "image = np.array(camera.value)\n",
    "\n",
    "jpeg_image = bgr8_to_jpeg(image)\n",
    "\n",
    "# Display image within Jupyter Notebook\n",
    "display(Image(data=jpeg_image))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "49c078b1",
   "metadata": {},
   "source": [
    "## Method\n",
    "\n",
    "Normally, for a regular autonomous vehicle, the car is programmed to identify the left and right lane markings, then develop the path and trajectory that the car should take. But this often involves multiple sensors and cameras that have both a wide field-of-view, as well as at various locations. But our Jetbot only has a singular camera, and as you may have seen in previous modules, the field-of-view is not particularly large. Thus, we are attempting a modified version, where we will detect the yellow middle markings, and have the Jetbot simply follow that dotted line.\n",
    "\n",
    "## Implementation\n",
    "\n",
    "To accomplish our task, we will undergo the following steps to our image.\n",
    "\n",
    "1. HSV Color Masking\n",
    "\n",
    "    One of the many ways to differentiate the yellow dotted line from the rest of the image, is to isolate the color yellow. To do this, we will use HSV color masking.\n",
    "\n",
    "2. Sobel Edge Detection\n",
    "\n",
    "    After we have isolated only the color yellow, we want to detect the edges, which highlight major changes in values between pixels. This also involves many other pre-processing techniques, including blurring and filtering based on area and direction.\n",
    "\n",
    "3. Midpoint Calculation\n",
    "\n",
    "    The Sobel Edge Detection will actually detect two vertical edges on each side of the yellow lane marker. But for our Jetbot, we want it to follow in the middle of these two points. This process is already completed, but it also involves filtering outliers and major deviations.\n",
    "\n",
    "When you run the code below, a few widgets should appear below. These widgets will allow you to modify various values and parameters, which you can tune to find the best values for detecting the yellow lane markings."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2300f94d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def adjust_gamma(image, gamma=1.2):\n",
    "    invGamma = 1.0 / gamma\n",
    "    table = np.array([(i / 255.0) ** invGamma * 255 for i in np.arange(256)]).astype(\"uint8\")\n",
    "    return cv2.LUT(image, table)\n",
    "\n",
    "def iqr_filter(x_list):\n",
    "    x = np.array(x_list)\n",
    "    q1, q3 = np.percentile(x, [25, 75])\n",
    "    iqr = q3 - q1\n",
    "    lower = q1 - 1.5 * iqr\n",
    "    upper = q3 + 1.5 * iqr\n",
    "    return [val for val in x if lower <= val <= upper]\n",
    "\n",
    "def get_yellow_lane_debug(image, apply_gamma=True, lower_yellow=(18, 80, 100), upper_yellow=(40, 255, 255)):\n",
    "    h, w = image.shape[:2]\n",
    "\n",
    "    if apply_gamma:\n",
    "        invGamma = 1.0 / 1.2\n",
    "        table = np.array([(i / 255.0) ** invGamma * 255 for i in np.arange(256)]).astype(\"uint8\")\n",
    "        image = cv2.LUT(image, table)\n",
    "\n",
    "    # === HSV yellow mask ===\n",
    "    blur = cv2.bilateralFilter(image, 9, 75, 75)\n",
    "    hsv = cv2.cvtColor(blur, cv2.COLOR_BGR2HSV)\n",
    "\n",
    "    lower_yellow = (18, 80, 100)\n",
    "    upper_yellow = (40, 255, 255)\n",
    "    mask_yellow = cv2.inRange(hsv, lower_yellow, upper_yellow)\n",
    "\n",
    "    # Morphology to clean specks\n",
    "    kernel = np.ones((5, 5), np.uint8)\n",
    "    mask_yellow = cv2.morphologyEx(mask_yellow, cv2.MORPH_OPEN, kernel, iterations=1)\n",
    "    mask_yellow = cv2.morphologyEx(mask_yellow, cv2.MORPH_CLOSE, kernel, iterations=1)\n",
    "\n",
    "    # Remove small blobs based on contour area\n",
    "    contours, _ = cv2.findContours(mask_yellow, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)\n",
    "    clean_mask = np.zeros_like(mask_yellow)\n",
    "    for cnt in contours:\n",
    "        if cv2.contourArea(cnt) > 150:\n",
    "            cv2.drawContours(clean_mask, [cnt], -1, 255, thickness=cv2.FILLED)\n",
    "    mask_yellow = clean_mask\n",
    "\n",
    "    # === Sobel X edges on yellow mask only ===\n",
    "    yellow_mask_blur = cv2.GaussianBlur(mask_yellow, (5, 5), 0)\n",
    "    sobelx = cv2.Sobel(yellow_mask_blur, cv2.CV_64F, 1, 0, ksize=3)\n",
    "    sobelx = np.absolute(sobelx)\n",
    "    sobelx = np.uint8(255 * sobelx / np.max(sobelx))\n",
    "    _, edge_mask = cv2.threshold(sobelx, 50, 255, cv2.THRESH_BINARY)\n",
    "\n",
    "    # === Get edge points ===\n",
    "    midline_points = []\n",
    "    left_points = []\n",
    "    right_points = []\n",
    "\n",
    "    for y in range(0, h, 4):\n",
    "        x_candidates = [x for x in range(w) if edge_mask[y, x] > 0]\n",
    "        if len(x_candidates) >= 3:\n",
    "            x_candidates = iqr_filter(x_candidates)\n",
    "\n",
    "            left_x = min(x_candidates)\n",
    "            right_x = max(x_candidates)\n",
    "            center_x = int(np.mean(x_candidates))\n",
    "\n",
    "            midline_points.append((center_x, y))\n",
    "            left_points.append((left_x, y))\n",
    "            right_points.append((right_x, y))\n",
    "\n",
    "    # === Midline smoothing ===\n",
    "    if midline_points:\n",
    "        x_vals = [x for x, y in midline_points]\n",
    "        x_smooth = medfilt(x_vals, kernel_size=5)\n",
    "        midline_points = list(zip(x_smooth, [y for _, y in midline_points]))\n",
    "\n",
    "    # === Visualization ===\n",
    "    overlay = image.copy()\n",
    "\n",
    "    for (x, y) in midline_points:\n",
    "        cv2.circle(overlay, (int(x), int(y)), 2, (0, 255, 0), -1)  # Green: midline\n",
    "    for (x, y) in left_points:\n",
    "        cv2.circle(overlay, (int(x), int(y)), 2, (255, 0, 0), -1)  # Blue: left edge\n",
    "    for (x, y) in right_points:\n",
    "        cv2.circle(overlay, (int(x), int(y)), 2, (0, 0, 255), -1)  # Red: right edge\n",
    "\n",
    "    return overlay, mask_yellow, sobelx, edge_mask, midline_points"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "68e7de0d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import threading\n",
    "\n",
    "# Create image widgets\n",
    "overlay_widget = widgets.Image(format='jpeg', width=300, height=300)\n",
    "yellow_mask_widget = widgets.Image(format='jpeg', width=300, height=300)\n",
    "sobel_widget = widgets.Image(format='jpeg', width=300, height=300)\n",
    "edge_mask_widget = widgets.Image(format='jpeg', width=300, height=300)\n",
    "\n",
    "# Display them with labels\n",
    "display(widgets.HBox([\n",
    "    widgets.Label(\"Overlay with midline\"),\n",
    "    overlay_widget,\n",
    "    widgets.Label(\"Yellow Mask\"),\n",
    "    yellow_mask_widget,\n",
    "    widgets.Label(\"Sobel X\"),\n",
    "    sobel_widget,\n",
    "    widgets.Label(\"Edge Mask\"),\n",
    "    edge_mask_widget\n",
    "]))\n",
    "\n",
    "# HSV sliders\n",
    "h_lower = widgets.IntSlider(value=18, min=0, max=179, description='H Lower')\n",
    "s_lower = widgets.IntSlider(value=80, min=0, max=255, description='S Lower')\n",
    "v_lower = widgets.IntSlider(value=100, min=0, max=255, description='V Lower')\n",
    "\n",
    "h_upper = widgets.IntSlider(value=40, min=0, max=179, description='H Upper')\n",
    "s_upper = widgets.IntSlider(value=255, min=0, max=255, description='S Upper')\n",
    "v_upper = widgets.IntSlider(value=255, min=0, max=255, description='V Upper')\n",
    "\n",
    "hsv_controls = widgets.VBox([\n",
    "    widgets.Label(\"Adjust HSV Thresholds\"),\n",
    "    h_lower, s_lower, v_lower,\n",
    "    h_upper, s_upper, v_upper\n",
    "])\n",
    "\n",
    "display(hsv_controls)\n",
    "\n",
    "\n",
    "# === Threaded Image Update ===\n",
    "def update_images():\n",
    "    while True:\n",
    "        img = camera.value\n",
    "        overlay, yellow_mask, sobelx, edge_mask, _ = get_yellow_lane_debug(img)\n",
    "\n",
    "        overlay_widget.value = bgr8_to_jpeg(overlay)\n",
    "        yellow_mask_widget.value = bgr8_to_jpeg(cv2.cvtColor(yellow_mask, cv2.COLOR_GRAY2BGR))\n",
    "        sobel_widget.value = bgr8_to_jpeg(cv2.cvtColor(sobelx, cv2.COLOR_GRAY2BGR))\n",
    "        edge_mask_widget.value = bgr8_to_jpeg(cv2.cvtColor(edge_mask, cv2.COLOR_GRAY2BGR))\n",
    "\n",
    "        time.sleep(0.1)  # Adjust refresh rate as needed\n",
    "\n",
    "threading.Thread(target=update_images, daemon=True).start()\n",
    "\n",
    "\n",
    "threading.Thread(target=update_images, daemon=True).start()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "81a5f8a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "from jetbot import Robot, Camera, bgr8_to_jpeg\n",
    "import cv2\n",
    "import numpy as np\n",
    "import ipywidgets as widgets\n",
    "from scipy.signal import medfilt\n",
    "from IPython.display import display\n",
    "import threading\n",
    "import time\n",
    "\n",
    "robot = Robot()\n",
    "camera = Camera.instance()\n",
    "\n",
    "# === HSV Control Sliders ===\n",
    "h_min = widgets.IntSlider(value=18, min=0, max=179, description='H Min')\n",
    "s_min = widgets.IntSlider(value=80, min=0, max=255, description='S Min')\n",
    "v_min = widgets.IntSlider(value=100, min=0, max=255, description='V Min')\n",
    "h_max = widgets.IntSlider(value=40, min=0, max=179, description='H Max')\n",
    "s_max = widgets.IntSlider(value=255, min=0, max=255, description='S Max')\n",
    "v_max = widgets.IntSlider(value=255, min=0, max=255, description='V Max')\n",
    "\n",
    "display(widgets.VBox([\n",
    "    widgets.Label(\"Adjust HSV range for yellow detection:\"),\n",
    "    h_min, h_max,\n",
    "    s_min, s_max,\n",
    "    v_min, v_max\n",
    "]))\n",
    "\n",
    "# === Image display widgets ===\n",
    "overlay_widget = widgets.Image(format='jpeg', width=300, height=300)\n",
    "yellow_mask_widget = widgets.Image(format='jpeg', width=300, height=300)\n",
    "sobel_widget = widgets.Image(format='jpeg', width=300, height=300)\n",
    "edge_mask_widget = widgets.Image(format='jpeg', width=300, height=300)\n",
    "\n",
    "display(widgets.HBox([\n",
    "    widgets.VBox([widgets.Label(\"Overlay with midline\"), overlay_widget]),\n",
    "    widgets.VBox([widgets.Label(\"Yellow Mask\"), yellow_mask_widget]),\n",
    "    widgets.VBox([widgets.Label(\"Sobel X\"), sobel_widget]),\n",
    "    widgets.VBox([widgets.Label(\"Edge Mask\"), edge_mask_widget])\n",
    "]))\n",
    "\n",
    "def adjust_gamma(image, gamma=1.2):\n",
    "    invGamma = 1.0 / gamma\n",
    "    table = np.array([(i / 255.0) ** invGamma * 255 for i in np.arange(256)]).astype(\"uint8\")\n",
    "    return cv2.LUT(image, table)\n",
    "\n",
    "def iqr_filter(x_list):\n",
    "    x = np.array(x_list)\n",
    "    q1, q3 = np.percentile(x, [25, 75])\n",
    "    iqr = q3 - q1\n",
    "    lower = q1 - 1.5 * iqr\n",
    "    upper = q3 + 1.5 * iqr\n",
    "    return [val for val in x if lower <= val <= upper]\n",
    "\n",
    "def get_yellow_lane_debug(image, apply_gamma=True):\n",
    "    h, w = image.shape[:2]\n",
    "\n",
    "    if apply_gamma:\n",
    "        image = adjust_gamma(image, gamma=1.2)\n",
    "\n",
    "    blur = cv2.bilateralFilter(image, 9, 75, 75)\n",
    "    hsv = cv2.cvtColor(blur, cv2.COLOR_BGR2HSV)\n",
    "\n",
    "    # Read HSV range from sliders\n",
    "    lower_yellow = (h_min.value, s_min.value, v_min.value)\n",
    "    upper_yellow = (h_max.value, s_max.value, v_max.value)\n",
    "    mask_yellow = cv2.inRange(hsv, lower_yellow, upper_yellow)\n",
    "\n",
    "    # Morphology to clean specks\n",
    "    kernel = np.ones((5, 5), np.uint8)\n",
    "    mask_yellow = cv2.morphologyEx(mask_yellow, cv2.MORPH_OPEN, kernel, iterations=1)\n",
    "    mask_yellow = cv2.morphologyEx(mask_yellow, cv2.MORPH_CLOSE, kernel, iterations=1)\n",
    "\n",
    "    # Remove small blobs\n",
    "    contours, _ = cv2.findContours(mask_yellow, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)\n",
    "    clean_mask = np.zeros_like(mask_yellow)\n",
    "    for cnt in contours:\n",
    "        if cv2.contourArea(cnt) > 150:\n",
    "            cv2.drawContours(clean_mask, [cnt], -1, 255, thickness=cv2.FILLED)\n",
    "    mask_yellow = clean_mask\n",
    "\n",
    "    # Edge detection\n",
    "    yellow_mask_blur = cv2.GaussianBlur(mask_yellow, (5, 5), 0)\n",
    "    sobelx = cv2.Sobel(yellow_mask_blur, cv2.CV_64F, 1, 0, ksize=3)\n",
    "    sobelx = np.absolute(sobelx)\n",
    "    if np.max(sobelx) > 0:\n",
    "        sobelx = np.uint8(255 * sobelx / np.max(sobelx))\n",
    "    else:\n",
    "        sobelx = np.zeros_like(sobelx, dtype=np.uint8)\n",
    "    _, edge_mask = cv2.threshold(sobelx, 50, 255, cv2.THRESH_BINARY)\n",
    "\n",
    "    midline_points = []\n",
    "    left_points = []\n",
    "    right_points = []\n",
    "\n",
    "    for y in range(0, h, 4):\n",
    "        x_candidates = [x for x in range(w) if edge_mask[y, x] > 0]\n",
    "        if len(x_candidates) >= 3:\n",
    "            x_candidates = iqr_filter(x_candidates)\n",
    "            left_x = min(x_candidates)\n",
    "            right_x = max(x_candidates)\n",
    "            center_x = int(np.mean(x_candidates))\n",
    "\n",
    "            midline_points.append((center_x, y))\n",
    "            left_points.append((left_x, y))\n",
    "            right_points.append((right_x, y))\n",
    "\n",
    "    if midline_points:\n",
    "        x_vals = [x for x, _ in midline_points]\n",
    "        x_smooth = medfilt(x_vals, kernel_size=5)\n",
    "        midline_points = list(zip(x_smooth, [y for _, y in midline_points]))\n",
    "\n",
    "    overlay = image.copy()\n",
    "    for (x, y) in midline_points:\n",
    "        cv2.circle(overlay, (int(x), int(y)), 2, (0, 255, 0), -1)\n",
    "    for (x, y) in left_points:\n",
    "        cv2.circle(overlay, (int(x), int(y)), 2, (255, 0, 0), -1)\n",
    "    for (x, y) in right_points:\n",
    "        cv2.circle(overlay, (int(x), int(y)), 2, (0, 0, 255), -1)\n",
    "\n",
    "    return overlay, mask_yellow, sobelx, edge_mask\n",
    "\n",
    "# === Periodic UI-safe update ===\n",
    "from IPython.display import clear_output\n",
    "from threading import Event\n",
    "\n",
    "stop_event = Event()\n",
    "\n",
    "def update_loop():\n",
    "    while not stop_event.is_set():\n",
    "        frame = camera.value\n",
    "        overlay, yellow_mask, sobelx, edge_mask = get_yellow_lane_debug(frame)\n",
    "\n",
    "        # Ensure UI-safe conversions\n",
    "        overlay_widget.value = bgr8_to_jpeg(overlay)\n",
    "        yellow_mask_widget.value = bgr8_to_jpeg(cv2.cvtColor(yellow_mask, cv2.COLOR_GRAY2BGR))\n",
    "        sobel_uint8 = np.uint8(sobelx)\n",
    "        sobel_widget.value = bgr8_to_jpeg(cv2.cvtColor(sobel_uint8, cv2.COLOR_GRAY2BGR))\n",
    "        edge_mask_widget.value = bgr8_to_jpeg(cv2.cvtColor(edge_mask, cv2.COLOR_GRAY2BGR))\n",
    "\n",
    "        time.sleep(0.1)\n",
    "\n",
    "thread = threading.Thread(target=update_loop, daemon=True)\n",
    "thread.start()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "567e98f3",
   "metadata": {},
   "source": [
    "## Bonus Challenge\n",
    "\n",
    "If you want an extra challenge, see if you can modify the code above to detect the left and right lane and find the midpoint trajectory from those lanes!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cffc8734",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-warning\">\n",
    "<b>INCLUDE CODE TO CALCULATE MIDPOINT FOR BONUS CHALLENGE</b>\n",
    "</div>"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
