{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "27bee32f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from jetbot import Robot, Camera, bgr8_to_jpeg\n",
    "import cv2\n",
    "import numpy as np\n",
    "from IPython.display import display, Image, clear_output\n",
    "import time\n",
    "import dt_apriltags\n",
    "from scipy.signal import medfilt\n",
    "import ipywidgets as widgets\n",
    "\n",
    "robot = Robot()\n",
    "camera = Camera.instance()\n",
    "detector = dt_apriltags.Detector()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2ae8ea74",
   "metadata": {},
   "source": [
    "## AprilTag Detection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "50b61b4c",
   "metadata": {},
   "outputs": [],
   "source": [
    "cam_mtx = [94.861, 119.511, 119.506, 114.969]\n",
    "AT_size = .065"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9114d7c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "while True:\n",
    "    clear_output(wait = True)\n",
    "    image = np.array(camera.value)\n",
    "    gray_frame = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "    detections = detector.detect(gray_frame, True, cam_mtx, AT_size)\n",
    "\n",
    "    for detection in detections:\n",
    "        corners = detection.corners\n",
    "        corners = [(int(x), int(y)) for (x, y) in corners]\n",
    "\n",
    "        cv2.polylines(image, [np.array(corners)], isClosed=True, color=(0, 255, 0), thickness=2)\n",
    "\n",
    "        tag_id = detection.tag_id\n",
    "        cv2.putText(image, f\"ID: {tag_id}\", (int(corners[0][0]), int(corners[0][1])-10),\n",
    "                    cv2.FONT_HERSHEY_SIMPLEX, 0.5, (255, 0, 0), 2)\n",
    "    \n",
    "    display(Image(data=bgr8_to_jpeg(image)))\n",
    "    if detections:\n",
    "        display(f\"ID: {detections[0].tag_id}\")\n",
    "        display(f\"Translation Pose: {detections[0].pose_t}\")\n",
    "        display(f\"Rotation Pose: {detections[0].pose_R}\")\n",
    "    time.sleep(0.05)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aa85a343",
   "metadata": {},
   "source": [
    "## Stop Sign Detection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6922e1d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "while True:\n",
    "\n",
    "    clear_output(wait = True)\n",
    "    orig_image = np.array(camera.value)\n",
    "    image = orig_image\n",
    "\n",
    "    # Convert to HSV (Hue, Saturation, Value) color space\n",
    "    hsv = cv2.cvtColor(image, cv2.COLOR_BGR2HSV)\n",
    "\n",
    "    # Define range of red color in HSV space\n",
    "    lower_red1 = np.array([0, 120, 70])\n",
    "    upper_red1 = np.array([10, 255, 255])\n",
    "    lower_red2 = np.array([170, 120, 70])\n",
    "    upper_red2 = np.array([180, 255, 255])\n",
    "\n",
    "    # Create a mask for red color\n",
    "    mask1 = cv2.inRange(hsv, lower_red1, upper_red1)\n",
    "    mask2 = cv2.inRange(hsv, lower_red2, upper_red2)\n",
    "    mask = mask1 | mask2\n",
    "\n",
    "    # Apply the mask to the image\n",
    "    red_traffic_signs = cv2.bitwise_and(image, image, mask=mask)\n",
    "\n",
    "    # Dilate image to get rid of white stop\n",
    "    dilated_image = cv2.dilate(red_traffic_signs, np.ones((5, 5), np.uint8), iterations = 2)\n",
    "    eroded_image = cv2.erode(dilated_image, np.ones((5, 5), np.uint8))\n",
    "\n",
    "    # # Define the sharpening kernel\n",
    "    # kernel = np.array([[-1, -1, -1],\n",
    "    #                 [-1, 9, -1],\n",
    "    #                 [-1, -1, -1]])\n",
    "\n",
    "    # # Apply the kernel to the image using filter2D\n",
    "    # sharpened_image = cv2.filter2D(eroded_image, -1, kernel)\n",
    "\n",
    "    # Convert to grayscale\n",
    "    gray = cv2.cvtColor(dilated_image, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "    # Apply Gaussian blur\n",
    "    blurred = cv2.GaussianBlur(gray, (5, 5), 0)\n",
    "\n",
    "    # Detect edges using Canny edge detector\n",
    "    edges = cv2.Canny(blurred, 100, 200)\n",
    "\n",
    "    # Find contours\n",
    "    contours, hierarchy = cv2.findContours(edges, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)\n",
    "\n",
    "    # Minimum area we look at\n",
    "    min_area = 800\n",
    "\n",
    "    # Loop through contours\n",
    "    for contour in contours:\n",
    "        contour_area = cv2.contourArea(contour)\n",
    "        if contour_area > min_area:\n",
    "            # Approximate the contour to a polygon\n",
    "            epsilon = 0.01 * cv2.arcLength(contour, True)\n",
    "            approx = cv2.approxPolyDP(contour, epsilon, True)\n",
    "\n",
    "            # If the shape has 8 vertices, it could be a stop sign (octagon)\n",
    "            if len(approx) == 8:\n",
    "                cv2.drawContours(orig_image, [approx], -1, (0, 255, 0), 2)\n",
    "                cv2.putText(orig_image, 'Stop Sign', tuple(approx[0][0]), cv2.FONT_HERSHEY_SIMPLEX, 1, (255, 0, 0), 2)\n",
    "                cv2.putText(orig_image, str(contour_area), (approx[0][0][0], approx[0][0][1] + 25), cv2.FONT_HERSHEY_SIMPLEX, 1, (255, 0, 0), 2)\n",
    "    \n",
    "    display(Image(data=bgr8_to_jpeg(orig_image)))\n",
    "    time.sleep(0.05)\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fc67e6bb",
   "metadata": {},
   "source": [
    "## Lane Detection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d0239ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "def adjust_gamma(image, gamma=1.2):\n",
    "    invGamma = 1.0 / gamma\n",
    "    table = np.array([(i / 255.0) ** invGamma * 255 for i in np.arange(256)]).astype(\"uint8\")\n",
    "    return cv2.LUT(image, table)\n",
    "\n",
    "def iqr_filter(x_list):\n",
    "    x = np.array(x_list)\n",
    "    q1, q3 = np.percentile(x, [25, 75])\n",
    "    iqr = q3 - q1\n",
    "    lower = q1 - 1.5 * iqr\n",
    "    upper = q3 + 1.5 * iqr\n",
    "    return [val for val in x if lower <= val <= upper]\n",
    "\n",
    "def get_lane_midline_inner_edges_outlier_debug(image, debug_prefix='debug', apply_gamma=True):\n",
    "    h, w = image.shape[:2]\n",
    "    mid_x = w // 2\n",
    "\n",
    "    if apply_gamma:\n",
    "        image = adjust_gamma(image, gamma=1.2)\n",
    "\n",
    "    # === Sobel X edges ===\n",
    "    gray = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n",
    "    sobelx = cv2.Sobel(gray, cv2.CV_64F, 1, 0, ksize=3)\n",
    "    sobelx = np.absolute(sobelx)\n",
    "    sobelx = np.uint8(255 * sobelx / np.max(sobelx))\n",
    "    _, sobel_bin = cv2.threshold(sobelx, 40, 255, cv2.THRESH_BINARY)\n",
    "\n",
    "    sobel_mask = np.zeros_like(sobel_bin)\n",
    "    sobel_mask[int(h * 0.45):, :] = sobel_bin[int(h * 0.45):, :]\n",
    "    sobel_mask = cv2.morphologyEx(sobel_mask, cv2.MORPH_CLOSE, np.ones((3, 3), np.uint8), iterations=1)\n",
    "\n",
    "    # === HSV yellow mask ===\n",
    "    hsv = cv2.cvtColor(image, cv2.COLOR_BGR2HSV)\n",
    "    hsv[..., 2] = cv2.equalizeHist(hsv[..., 2])\n",
    "    mask_yellow = cv2.inRange(hsv, (10, 30, 40), (45, 255, 255))\n",
    "    mask_yellow = cv2.morphologyEx(mask_yellow, cv2.MORPH_CLOSE, np.ones((3, 3), np.uint8), iterations=1)\n",
    "    yellow_sobel = cv2.bitwise_and(mask_yellow, sobel_mask)\n",
    "\n",
    "    # === Extract left (yellow âˆ© sobel) and right (sobel only) points ===\n",
    "    left_pts = []\n",
    "    right_pts = []\n",
    "\n",
    "    contours, _ = cv2.findContours(sobel_mask, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_NONE)\n",
    "    for cnt in contours:\n",
    "        if cv2.contourArea(cnt) < 20:\n",
    "            continue\n",
    "        for x, y in cnt[:, 0, :]:\n",
    "            if y < int(h * 0.45):\n",
    "                continue\n",
    "            if x < mid_x and yellow_sobel[y, x] > 0:\n",
    "                left_pts.append((x, y))\n",
    "            elif x > mid_x:\n",
    "                right_pts.append((x, y))\n",
    "\n",
    "    # === Overlay image ===\n",
    "    out_img = image.copy()\n",
    "    if out_img.ndim == 2:\n",
    "        out_img = cv2.cvtColor(out_img, cv2.COLOR_GRAY2BGR)\n",
    "\n",
    "    mid_pts = []\n",
    "    max_slope_deg = 30\n",
    "    prev_xc, prev_y = None, None\n",
    "\n",
    "    for y in range(int(h * 0.45), h, 4):\n",
    "        x_lefts = [x for (x, yy) in left_pts if abs(yy - y) <= 2]\n",
    "        x_rights = [x for (x, yy) in right_pts if abs(yy - y) <= 2]\n",
    "\n",
    "        if len(x_lefts) >= 3:\n",
    "            x_lefts = iqr_filter(x_lefts)\n",
    "        if len(x_rights) >= 3:\n",
    "            x_rights = iqr_filter(x_rights)\n",
    "\n",
    "        if not x_lefts or not x_rights:\n",
    "            continue\n",
    "\n",
    "        x_left = max(x_lefts)\n",
    "        x_right = min(x_rights)\n",
    "        x_center = (x_left + x_right) // 2\n",
    "\n",
    "        # Slope filtering\n",
    "        if prev_xc is not None:\n",
    "            dx = x_center - prev_xc\n",
    "            dy = y - prev_y\n",
    "            angle = np.degrees(np.arctan2(abs(dx), dy + 1e-5))\n",
    "            if angle > max_slope_deg:\n",
    "                continue\n",
    "\n",
    "        mid_pts.append((x_center, y))\n",
    "        prev_xc, prev_y = x_center, y\n",
    "\n",
    "        # Draw edges\n",
    "        cv2.circle(out_img, (int(x_left), int(y)), 2, (255, 0, 0), -1)\n",
    "        cv2.circle(out_img, (int(x_right), int(y)), 2, (0, 0, 255), -1)\n",
    "\n",
    "    # === Midline smoothing ===\n",
    "    if mid_pts:\n",
    "        x_vals = [x for x, y in mid_pts]\n",
    "        x_smooth = medfilt(x_vals, kernel_size=5)\n",
    "        mid_pts = list(zip(x_smooth, [y for _, y in mid_pts]))\n",
    "\n",
    "    for x_c, y in mid_pts:\n",
    "        cv2.circle(out_img, (int(x_c), int(y)), 2, (0, 255, 0), -1)\n",
    "\n",
    "    # === Save debug outputs ===\n",
    "    if debug_prefix:\n",
    "        cv2.imwrite(f\"{debug_prefix}_sobel.jpg\", sobel_bin)\n",
    "        cv2.imwrite(f\"{debug_prefix}_yellow.jpg\", mask_yellow)\n",
    "        cv2.imwrite(f\"{debug_prefix}_final_combined.jpg\", sobel_mask)\n",
    "        cv2.imwrite(f\"{debug_prefix}_overlay.jpg\", out_img)\n",
    "\n",
    "    # === Deviation computation ===\n",
    "    if mid_pts:\n",
    "        x_center_last = mid_pts[-1][0]\n",
    "        deviation = (x_center_last - mid_x) / mid_x\n",
    "    else:\n",
    "        deviation = 0.0\n",
    "\n",
    "    return out_img, deviation\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "748590b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import threading\n",
    "image = widgets.Image(format='jpeg', width=300, height=300)\n",
    "display(image)\n",
    "\n",
    "def update_image():\n",
    "    while True:\n",
    "        img = camera.value\n",
    "        out_img, dev = get_lane_midline_inner_edges_outlier_debug(img, None)\n",
    "        image.value = bgr8_to_jpeg(out_img)\n",
    "        display(dev)\n",
    "        time.sleep(0.01)\n",
    "\n",
    "threading.Thread(target=update_image, daemon=True).start()"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
