{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "661cd3b0",
   "metadata": {},
   "source": [
    "# Module 6: Mid-Line Detection\n",
    "\n",
    "This is where we start to get to the main application for our Jetbot. We want to be able to detect the lane and find the trajectory for which our robot should follow. This will involve some of the lessons we have previously learned, and applying them in a separate context.\n",
    "\n",
    "This module should follow Module 5: Road Sign Detection\n",
    "\n",
    "Below is our normal starter code for initializing all variables and packages."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2088876e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from jetbot import Robot, Camera, bgr8_to_jpeg\n",
    "import cv2\n",
    "import numpy as np\n",
    "import ipywidgets as widgets\n",
    "from scipy.signal import medfilt\n",
    "from IPython.display import display, Image, clear_output\n",
    "import time\n",
    "import threading\n",
    "import os"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "49c078b1",
   "metadata": {},
   "source": [
    "## Method\n",
    "\n",
    "Normally, for a regular autonomous vehicle, the car is programmed to identify the left and right lane markings, then develop the path and trajectory that the car should take. But this often involves multiple sensors and cameras that have both a wide field-of-view, as well as at various locations. But our Jetbot only has a singular camera, and as you may have seen in previous modules, the field-of-view is not particularly large. Thus, we are attempting a modified version, where we will detect the yellow middle markings, and have the Jetbot simply follow that dotted line.\n",
    "\n",
    "## Implementation\n",
    "\n",
    "To accomplish our task, we will undergo the following steps to our image.\n",
    "\n",
    "1. HSV Color Masking\n",
    "\n",
    "    One of the many ways to differentiate the yellow dotted line from the rest of the image, is to isolate the color yellow. To do this, we will use HSV color masking.\n",
    "\n",
    "2. Sobel Edge Detection\n",
    "\n",
    "    After we have isolated only the color yellow, we want to detect the edges, which highlight major changes in values between pixels. This also involves many other pre-processing techniques, including blurring and filtering based on area and direction.\n",
    "    \n",
    "    Sobel Edge detection also primarily relies on directionality when determining edges. This means we can isolate the vertical edges in particular, which will be useful for our line tracking.\n",
    "\n",
    "3. Midpoint Calculation\n",
    "\n",
    "    The Sobel Edge Detection will actually detect two vertical edges on each side of the yellow lane marker. But for our Jetbot, we want it to follow in the middle of these two points. This process is already completed, but it also involves filtering outliers and major deviations."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "11673b72",
   "metadata": {},
   "source": [
    "### Activity\n",
    "\n",
    "Similar to Module 5, we are going to take photos with our <i><b>Camera_Capture.ipynb</i></b> notebook of various angles and positions of the yellow lane marking. Once you do that, run the following code below to confirm that the images did save."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb896084",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Change folder name HERE!!!\n",
    "SAVE_DIR = \"lane_images\"\n",
    "# Optional: Change filename here to look at different image.\n",
    "filename = \"image_0.jpg\"\n",
    "# Displays the image\n",
    "filepath = os.path.join(SAVE_DIR, filename)\n",
    "frame = cv2.imread(filepath)\n",
    "display(Image(data=bgr8_to_jpeg(frame)))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "73aad904",
   "metadata": {},
   "source": [
    "This next block has many of the functions that we will use to detect our yellow center line. When you run the code below, a few widgets should appear below. These widgets will allow you to modify various values and parameters, which you can tune to find the best values for detecting the yellow lane markings."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19953e4b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Brighten Gamma of Image\n",
    "def adjust_gamma(image, gamma=1.2):\n",
    "    invGamma = 1.0 / gamma\n",
    "    table = np.array([(i / 255.0) ** invGamma * 255 for i in np.arange(256)]).astype(\"uint8\")\n",
    "    return cv2.LUT(image, table)\n",
    "\n",
    "# Filter based on inter-quartile range (remove outliers)\n",
    "def iqr_filter(x_list):\n",
    "    x = np.array(x_list)\n",
    "    q1, q3 = np.percentile(x, [25, 75])\n",
    "    iqr = q3 - q1\n",
    "    lower = q1 - 1.5 * iqr\n",
    "    upper = q3 + 1.5 * iqr\n",
    "    return [val for val in x if lower <= val <= upper]\n",
    "\n",
    "# Calculate midpoints based on masked image\n",
    "def lane_midpoint(masked_image):\n",
    "    midline_points = []\n",
    "    left_points = []\n",
    "    right_points = []\n",
    "    h, w = masked_image.shape[:2]\n",
    "\n",
    "    for y in range(0, h, 4):\n",
    "        x_candidates = [x for x in range(w) if masked_image[y, x] > 0]\n",
    "        if len(x_candidates) >= 3:\n",
    "            x_candidates = iqr_filter(x_candidates)\n",
    "            left_x = min(x_candidates)\n",
    "            right_x = max(x_candidates)\n",
    "            center_x = int(np.mean(x_candidates))\n",
    "\n",
    "            midline_points.append((center_x, y))\n",
    "            left_points.append((left_x, y))\n",
    "            right_points.append((right_x, y))\n",
    "\n",
    "    if midline_points:\n",
    "        x_vals = [x for x, _ in midline_points]\n",
    "        x_smooth = medfilt(x_vals, kernel_size=5)\n",
    "        midline_points = list(zip(x_smooth, [y for _, y in midline_points]))\n",
    "    \n",
    "    return midline_points, left_points, right_points\n",
    "\n",
    "# Isolate Yellow Lane Marking\n",
    "def get_yellow_lane(image, apply_gamma=True):\n",
    "\n",
    "    # Brighten Images\n",
    "    if apply_gamma:\n",
    "        image = adjust_gamma(image, gamma=1.2)\n",
    "\n",
    "    # Blur and Convert to HSV Color Space\n",
    "    blur = cv2.bilateralFilter(image, 9, 75, 75)\n",
    "    hsv = cv2.cvtColor(blur, cv2.COLOR_BGR2HSV)\n",
    "\n",
    "    # Read HSV range from sliders\n",
    "    lower_yellow = (h_min.value, s_min.value, v_min.value)\n",
    "    upper_yellow = (h_max.value, s_max.value, v_max.value)\n",
    "    mask_yellow = cv2.inRange(hsv, lower_yellow, upper_yellow)\n",
    "\n",
    "    # Morphology to clean specks (Dilation and Erosion)\n",
    "    kernel = np.ones((5, 5), np.uint8)\n",
    "    opened = cv2.morphologyEx(mask_yellow, cv2.MORPH_OPEN, kernel, iterations=1)\n",
    "    closed = cv2.morphologyEx(opened, cv2.MORPH_CLOSE, kernel, iterations=1)\n",
    "\n",
    "    # Remove small blobs\n",
    "    contours, _ = cv2.findContours(closed, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)\n",
    "    clean_mask = np.zeros_like(closed)\n",
    "    for cnt in contours:\n",
    "        if cv2.contourArea(cnt) > 150:\n",
    "            cv2.drawContours(clean_mask, [cnt], -1, 255, thickness=cv2.FILLED)\n",
    "    contour_mask = clean_mask\n",
    "\n",
    "    # Edge detection\n",
    "    yellow_mask_blur = cv2.GaussianBlur(contour_mask, (5, 5), 0)\n",
    "    sobelx = cv2.Sobel(yellow_mask_blur, cv2.CV_64F, 1, 0, ksize=3)\n",
    "    sobelx = np.absolute(sobelx)\n",
    "    if np.max(sobelx) > 0:\n",
    "        sobelx = np.uint8(255 * sobelx / np.max(sobelx))\n",
    "    else:\n",
    "        sobelx = np.zeros_like(sobelx, dtype=np.uint8)\n",
    "    _, edge_mask = cv2.threshold(sobelx, 50, 255, cv2.THRESH_BINARY)\n",
    "\n",
    "    return mask_yellow, edge_mask\n",
    "\n",
    "\n",
    "# Updating Loop\n",
    "stop_event = threading.Event()\n",
    "\n",
    "def update_loop():\n",
    "    while not stop_event.is_set():\n",
    "        image_capture = frame\n",
    "        \n",
    "        yellow_mask, edge_mask = get_yellow_lane(frame)\n",
    "\n",
    "        midline_points, left_points, right_points = lane_midpoint(edge_mask)\n",
    "\n",
    "        overlay = frame.copy()\n",
    "        for (x, y) in midline_points:\n",
    "            cv2.circle(overlay, (int(x), int(y)), 2, (0, 255, 0), -1)\n",
    "        for (x, y) in left_points:\n",
    "            cv2.circle(overlay, (int(x), int(y)), 2, (255, 0, 0), -1)\n",
    "        for (x, y) in right_points:\n",
    "            cv2.circle(overlay, (int(x), int(y)), 2, (0, 0, 255), -1)\n",
    "\n",
    "        # Ensure UI-safe conversions\n",
    "        overlay_widget.value = bgr8_to_jpeg(overlay)\n",
    "        yellow_mask_widget.value = bgr8_to_jpeg(cv2.cvtColor(yellow_mask, cv2.COLOR_GRAY2BGR))\n",
    "        edge_mask_widget.value = bgr8_to_jpeg(cv2.cvtColor(edge_mask, cv2.COLOR_GRAY2BGR))\n",
    "\n",
    "        time.sleep(0.1)\n",
    "\n",
    "# Yellow HSV Slider Widgets\n",
    "h_min = widgets.IntSlider(value=0, min=0, max=180, description='H Min')\n",
    "s_min = widgets.IntSlider(value=0, min=0, max=255, description='S Min')\n",
    "v_min = widgets.IntSlider(value=0, min=0, max=255, description='V Min')\n",
    "h_max = widgets.IntSlider(value=180, min=0, max=180, description='H Max')\n",
    "s_max = widgets.IntSlider(value=255, min=0, max=255, description='S Max')\n",
    "v_max = widgets.IntSlider(value=255, min=0, max=255, description='V Max')\n",
    "\n",
    "display(widgets.VBox([\n",
    "    widgets.Label(\"Adjust HSV range for yellow detection:\"),\n",
    "    widgets.HBox([h_min, h_max]),\n",
    "    widgets.HBox([s_min, s_max]),\n",
    "    widgets.HBox([v_min, v_max])\n",
    "]))\n",
    "\n",
    "# Image Debugging Widgets\n",
    "overlay_widget = widgets.Image(format='jpeg', width=300, height=300)\n",
    "yellow_mask_widget = widgets.Image(format='jpeg', width=300, height=300)\n",
    "edge_mask_widget = widgets.Image(format='jpeg', width=300, height=300)\n",
    "\n",
    "display(widgets.HBox([\n",
    "    widgets.VBox([widgets.Label(\"Overlay with midline\"), overlay_widget]),\n",
    "    widgets.VBox([widgets.Label(\"Yellow Mask\"), yellow_mask_widget]),\n",
    "    widgets.VBox([widgets.Label(\"Edge Mask\"), edge_mask_widget])\n",
    "]))\n",
    "\n",
    "# Starts the Feed\n",
    "thread = threading.Thread(target=update_loop, daemon=True)\n",
    "thread.start()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c6cbe99",
   "metadata": {},
   "outputs": [],
   "source": [
    "stop_event.set()\n",
    "thread.join()\n",
    "stop_event.clear()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7772ed1c",
   "metadata": {},
   "source": [
    "## Live Camera Testing\n",
    "\n",
    "Once you find values and tracking that you like, try it with the live camera feed from the <b><span style=\"color:#154734\">JetBot</span></b>.\n",
    "\n",
    "You will need to update any values you changed above. These do not save between blocks."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed532b36",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize our robot\n",
    "robot = Robot()\n",
    "# Initialize our camera\n",
    "camera = Camera.instance()\n",
    "\n",
    "# Save image data (modified to be numpy array)\n",
    "image = np.array(camera.value)\n",
    "\n",
    "jpeg_image = bgr8_to_jpeg(image)\n",
    "\n",
    "# Display image within Jupyter Notebook\n",
    "display(Image(data=jpeg_image))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aaeb959e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Updating Loop\n",
    "stop_event = threading.Event()\n",
    "\n",
    "def update_loop():\n",
    "    while not stop_event.is_set():\n",
    "        frame = camera.value\n",
    "        \n",
    "        yellow_mask, edge_mask = get_yellow_lane(frame)\n",
    "\n",
    "        midline_points, left_points, right_points = lane_midpoint(edge_mask)\n",
    "\n",
    "        overlay = frame.copy()\n",
    "        for (x, y) in midline_points:\n",
    "            cv2.circle(overlay, (int(x), int(y)), 2, (0, 255, 0), -1)\n",
    "        for (x, y) in left_points:\n",
    "            cv2.circle(overlay, (int(x), int(y)), 2, (255, 0, 0), -1)\n",
    "        for (x, y) in right_points:\n",
    "            cv2.circle(overlay, (int(x), int(y)), 2, (0, 0, 255), -1)\n",
    "\n",
    "        # Ensure UI-safe conversions\n",
    "        overlay_widget.value = bgr8_to_jpeg(overlay)\n",
    "        yellow_mask_widget.value = bgr8_to_jpeg(cv2.cvtColor(yellow_mask, cv2.COLOR_GRAY2BGR))\n",
    "        edge_mask_widget.value = bgr8_to_jpeg(cv2.cvtColor(edge_mask, cv2.COLOR_GRAY2BGR))\n",
    "\n",
    "        time.sleep(0.1)\n",
    "\n",
    "# Yellow HSV Slider Widgets\n",
    "h_min = widgets.IntSlider(value=0, min=0, max=180, description='H Min')\n",
    "s_min = widgets.IntSlider(value=0, min=0, max=255, description='S Min')\n",
    "v_min = widgets.IntSlider(value=0, min=0, max=255, description='V Min')\n",
    "h_max = widgets.IntSlider(value=180, min=0, max=180, description='H Max')\n",
    "s_max = widgets.IntSlider(value=255, min=0, max=255, description='S Max')\n",
    "v_max = widgets.IntSlider(value=255, min=0, max=255, description='V Max')\n",
    "\n",
    "display(widgets.VBox([\n",
    "    widgets.Label(\"Adjust HSV range for yellow detection:\"),\n",
    "    widgets.HBox([h_min, h_max]),\n",
    "    widgets.HBox([s_min, s_max]),\n",
    "    widgets.HBox([v_min, v_max])\n",
    "]))\n",
    "\n",
    "# Image Debugging Widgets\n",
    "overlay_widget = widgets.Image(format='jpeg', width=300, height=300)\n",
    "yellow_mask_widget = widgets.Image(format='jpeg', width=300, height=300)\n",
    "edge_mask_widget = widgets.Image(format='jpeg', width=300, height=300)\n",
    "\n",
    "display(widgets.HBox([\n",
    "    widgets.VBox([widgets.Label(\"Overlay with midline\"), overlay_widget]),\n",
    "    widgets.VBox([widgets.Label(\"Yellow Mask\"), yellow_mask_widget]),\n",
    "    widgets.VBox([widgets.Label(\"Edge Mask\"), edge_mask_widget])\n",
    "]))\n",
    "\n",
    "# Starts the Feed\n",
    "camera.start()\n",
    "thread = threading.Thread(target=update_loop, daemon=True)\n",
    "thread.start()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f99f01b3",
   "metadata": {},
   "source": [
    "Make sure to move the <b><span style=\"color:#154734\">JetBot</span></b> around to ensure the camera sees the yellow lane markings at various angles and locations!!! Don't just test the camera in one location!\n",
    "\n",
    "The code below allows you to break the loop in case you want to edit anything in the function. Run the following block, edit anything you need to above, then run the blocks from that point downwards."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d655f47",
   "metadata": {},
   "outputs": [],
   "source": [
    "stop_event.set()\n",
    "thread.join()\n",
    "stop_event.clear()\n",
    "camera.stop()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "567e98f3",
   "metadata": {},
   "source": [
    "## Bonus Challenge\n",
    "\n",
    "If you want an extra challenge, see if you can modify the code above to detect the left and right lane and find the midpoint trajectory from those lanes!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "059d5e13",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Image Debugging Widgets\n",
    "overlay_widget = widgets.Image(format='jpeg', width=300, height=300)\n",
    "lane_mask_widget = widgets.Image(format='jpeg', width=300, height=300)\n",
    "\n",
    "display(widgets.HBox([\n",
    "    widgets.VBox([widgets.Label(\"Overlay with midline\"), overlay_widget]),\n",
    "    widgets.VBox([widgets.Label(\"Lane Mask\"), lane_mask_widget])\n",
    "]))\n",
    "\n",
    "# Brighten Gamma of Image\n",
    "def adjust_gamma(image, gamma=1.2):\n",
    "    invGamma = 1.0 / gamma\n",
    "    table = np.array([(i / 255.0) ** invGamma * 255 for i in np.arange(256)]).astype(\"uint8\")\n",
    "    return cv2.LUT(image, table)\n",
    "\n",
    "# Filter based on inter-quartile range (remove outliers)\n",
    "def iqr_filter(x_list):\n",
    "    x = np.array(x_list)\n",
    "    q1, q3 = np.percentile(x, [25, 75])\n",
    "    iqr = q3 - q1\n",
    "    lower = q1 - 1.5 * iqr\n",
    "    upper = q3 + 1.5 * iqr\n",
    "    return [val for val in x if lower <= val <= upper]\n",
    "\n",
    "# Calculate midpoints based on masked image\n",
    "def lane_midpoint(masked_image):\n",
    "    midline_points = []\n",
    "    left_points = []\n",
    "    right_points = []\n",
    "    h, w = masked_image.shape[:2]\n",
    "\n",
    "    for y in range(0, h, 4):\n",
    "        x_candidates = [x for x in range(w) if masked_image[y, x] > 0]\n",
    "        if len(x_candidates) >= 3:\n",
    "            x_candidates = iqr_filter(x_candidates)\n",
    "            left_x = min(x_candidates)\n",
    "            right_x = max(x_candidates)\n",
    "            center_x = int(np.mean(x_candidates))\n",
    "\n",
    "            midline_points.append((center_x, y))\n",
    "            left_points.append((left_x, y))\n",
    "            right_points.append((right_x, y))\n",
    "\n",
    "    if midline_points:\n",
    "        x_vals = [x for x, _ in midline_points]\n",
    "        x_smooth = medfilt(x_vals, kernel_size=5)\n",
    "        midline_points = list(zip(x_smooth, [y for _, y in midline_points]))\n",
    "    \n",
    "    return midline_points, left_points, right_points\n",
    "\n",
    "# Isolate Yellow Lane Marking\n",
    "def get_lane_markings(image, apply_gamma=True):\n",
    "    # TODO: Add Code Here!\n",
    "    # Can add more returns for debugging\n",
    "    return lane_mask\n",
    "\n",
    "stop_event = threading.Event()\n",
    "\n",
    "def update_loop():\n",
    "    while not stop_event.is_set():\n",
    "        frame = camera.value\n",
    "\n",
    "        # Can add more returns for debugging.\n",
    "        lane_mask = get_lane_markings(frame)\n",
    "\n",
    "        midline_points, left_points, right_points = lane_midpoint(lane_mask)\n",
    "\n",
    "        overlay = frame.copy()\n",
    "        for (x, y) in midline_points:\n",
    "            cv2.circle(overlay, (int(x), int(y)), 2, (0, 255, 0), -1)\n",
    "        for (x, y) in left_points:\n",
    "            cv2.circle(overlay, (int(x), int(y)), 2, (255, 0, 0), -1)\n",
    "        for (x, y) in right_points:\n",
    "            cv2.circle(overlay, (int(x), int(y)), 2, (0, 0, 255), -1)\n",
    "\n",
    "        # Ensure UI-safe conversions\n",
    "        overlay_widget.value = bgr8_to_jpeg(overlay)\n",
    "        lane_mask_widget.value = bgr8_to_jpeg(cv2.cvtColor(lane_mask, cv2.COLOR_GRAY2BGR))\n",
    "\n",
    "        time.sleep(0.1)\n",
    "\n",
    "camera.start()\n",
    "thread = threading.Thread(target=update_loop, daemon=True)\n",
    "thread.start()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb3b5dfb",
   "metadata": {},
   "outputs": [],
   "source": [
    "stop_event.set()\n",
    "thread.join()\n",
    "stop_event.clear()\n",
    "camera.stop()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
